mlflow:
  experiment_name: "MARLExperiment"

ray:
  num_cpus: 4

unity_env:
  base_port: 5004
  no_graphics: false

env_config:
  initial_agent_count: 2
  episode_horizon: 1000

ppo_config:
  framework: "torch"
  num_gpus: 0

multi_agent:
  policies:
    shared_policy:
      # Observation and action spaces will be set programmatically

rollouts:
  num_rollout_workers: 2
  num_envs_per_worker: 1
  rollout_fragment_length: 200
  batch_mode: "truncate_episodes"

training:
  train_batch_size: 4000
  sgd_minibatch_size: 128
  num_sgd_iter: 30
  lr: 3.0e-4
  gamma: 0.99
  lambda: 0.95
  clip_param: 0.2
  vf_clip_param: 10.0
  entropy_coeff: 0.01
  kl_coeff: 0.5
  vf_loss_coeff: 1.0

environment:
  disable_env_checking: true

stop:
  training_iteration: 1
