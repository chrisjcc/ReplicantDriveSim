# config_schema.yaml

mlflow:
  experiment_name: str()

ray_init:
  num_cpus: int(min=1)
  num_gpus: int(min=0)

unity_env:
  worker_id: int(min=0)
  base_port: int(min=1024, max=65535)
  no_graphics: bool()
  seed: int(min=0)
  log_folder: str()

env_config:
  initial_agent_count: int(min=1)
  episode_horizon: int(min=1)
  rewards:
    off_road_penalty: num()
    on_road_reward: num()
    collision_with_other_agent_penalty: num()
    median_crossing_penalty: num()

ppo_config:
  framework: enum('torch', 'tf', 'tf2')
  num_gpus: int(min=0)

multi_agent:
  policies:
    shared_policy:
      observation_space:
        type: enum('Box', 'Discrete')  # Restricting to common RL spaces
        shape: list(int(min=1), len=1)  # Ensuring a single-dimension shape list
      action_space:
        type: enum('Box', 'Discrete', 'Tuple')
        shape:
          discrete: list(int(min=1), len=1)  # Expecting a list with at least one discrete action
          continuous: list(int(min=1), len=1)  # Expecting a list with at least one continuous action

env_runners:
  num_env_runners: int(min=1)
  num_envs_per_env_runner: int(min=1)
  num_cpus_per_env_runner: int(min=1)
  num_gpus_per_env_runner: int(min=0)
  rollout_fragment_length: str()  # Auto or numerical values parsed externally
  batch_mode: enum('truncate_episodes', 'complete_episodes')

training:
  num_workers: int(min=1)
  num_gpus: int(min=0)
  train_batch_size: int(min=1)
  sgd_minibatch_size: int(min=1)
  num_epochs: int(min=1)
  lr: num(min=0)
  gamma: num(min=0, max=1)
  lambda: num(min=0, max=1)
  clip_param: num(min=0)
  vf_clip_param: num(min=0)
  entropy_coeff: num(min=0)
  kl_coeff: num(min=0)
  vf_loss_coeff: num(min=0)
  checkpoint_at_end: bool()
  checkpoint_freq: int(min=1)
  num_to_keep: int(min=1)

environment:
  disable_env_checking: bool()

stop:
  training_iteration: int(min=1)
